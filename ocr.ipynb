{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start recognize text from image ---\n",
      "ig = Pegaso Tees Notified vide SRO #677\n",
      "KEP ETE ete Semets eee\n",
      "Peers Ne tart\n",
      "TARIFF CATEGORY / PARTICULARS\n",
      "\n",
      "For Sanctioned load less than § KW\n",
      "Upto 50 Units\n",
      "For Consumption exceeding 50 Units,\n",
      "11 - 400 Units,\n",
      "101 - 200 Units\n",
      "|201 - 300 Units’\n",
      "1301 - 700 Units.\n",
      "Above 700 Units\n",
      "For Sanctioned load $ KW & above\n",
      "[Time of Use\n",
      "\n",
      "[As per Authority's dacision Residential Consumers will be given tha benefit of only one previous slab\n",
      "\n",
      "Consumption exceeding S¢ units but not exceeding 200 units will charged under.the 1-100 slab,\n",
      "\n",
      "Under tariff A-1, there shall be minimum monthly custamer charge at the following rates:\n",
      "\n",
      "a} Single Phase Connections: “ Rs. 75/- per consumer par month .\n",
      "\n",
      "b] Three Phase Connections: Rs, 150/- per consumer per month, ~ aes Scer\n",
      "\n",
      "Rs/kW/M\n",
      "------ Done -------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Path of working folder on Disk\n",
    "src_path = \"F:/ocr image/kesc.jpg\"\n",
    "\n",
    "def get_string(img_path):\n",
    "    # Read image with opencv\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Convert to gray\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply dilation and erosion to remove some noise\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    img = cv2.dilate(img, kernel, iterations=1)\n",
    "    img = cv2.erode(img, kernel, iterations=1)\n",
    "\n",
    "    # Write image after removed noise\n",
    "    cv2.imwrite(src_path + \"removed_noise.png\", img)\n",
    "\n",
    "    #  Apply threshold to get image with only black and white\n",
    "    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "\n",
    "    # Write the image after apply opencv to do some ...\n",
    "    cv2.imwrite(src_path + \"thres.png\", img)\n",
    "\n",
    "    # Recognize text with tesseract for python\n",
    "    result = pytesseract.image_to_string(Image.open(src_path + \"thres.png\"))\n",
    "\n",
    "    # Remove template file\n",
    "    #os.remove(temp)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "print('--- Start recognize text from image ---')\n",
    "print(get_string(src_path))\n",
    "print(\"------ Done -------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your file name: new_file\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    global file_name\n",
    "    file_name = input(\"Enter your file name: \") + \".txt\"\n",
    "    new_file = open(file_name ,\"w+\")\n",
    "    new_file.write(get_string(src_path))\n",
    "    new_file.close()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ig = Pegaso Tees Notified vide SRO #677\n",
      "KEP ETE ete Semets eee\n",
      "Peers Ne tart\n",
      "TARIFF CATEGORY / PARTICULARS\n",
      "\n",
      "For Sanctioned load less than § KW\n",
      "Upto 50 Units\n",
      "For Consumption exceeding 50 Units,\n",
      "11 - 400 Units,\n",
      "101 - 200 Units\n",
      "|201 - 300 Units’\n",
      "1301 - 700 Units.\n",
      "Above 700 Units\n",
      "For Sanctioned load $ KW & above\n",
      "[Time of Use\n",
      "\n",
      "[As per Authority's dacision Residential Consumers will be given tha benefit of only one previous slab\n",
      "\n",
      "Consumption exceeding S¢ units but not exceeding 200 units will charged under.the 1-100 slab,\n",
      "\n",
      "Under tariff A-1, there shall be minimum monthly custamer charge at the following rates:\n",
      "\n",
      "a} Single Phase Connections: “ Rs. 75/- per consumer par month .\n",
      "\n",
      "b] Three Phase Connections: Rs, 150/- per consumer per month, ~ aes Scer\n",
      "\n",
      "Rs/kW/M\n"
     ]
    }
   ],
   "source": [
    "open_file = open(file_name, \"r\")\n",
    "contents = open_file.read()\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Shahzad\n",
      "[nltk_data]     Ahsan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Shahzad Ahsan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = \"My name is Muhammad Shahzad Ahsan. I'm 22 years old. I'm currenlty working in Easy Way Agency and my salary is 55000/-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('My', 'PRP$'),\n",
       " ('name', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('Muhammad', 'NNP'),\n",
       " ('Shahzad', 'NNP'),\n",
       " ('Ahsan', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " (\"'m\", 'VBP'),\n",
       " ('22', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " (\"'m\", 'VBP'),\n",
       " ('currenlty', 'JJ'),\n",
       " ('working', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Easy', 'NNP'),\n",
       " ('Way', 'NNP'),\n",
       " ('Agency', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('my', 'PRP$'),\n",
       " ('salary', 'JJ'),\n",
       " ('is', 'VBZ'),\n",
       " ('55000/-', 'JJ')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = preprocess(ex)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'NP: {<DT>?<JJ>*<NN>}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  My/PRP$\n",
      "  (NP name/NN)\n",
      "  is/VBZ\n",
      "  Muhammad/NNP\n",
      "  Shahzad/NNP\n",
      "  Ahsan/NNP\n",
      "  ./.\n",
      "  I/PRP\n",
      "  'm/VBP\n",
      "  22/CD\n",
      "  years/NNS\n",
      "  old/JJ\n",
      "  ./.\n",
      "  I/PRP\n",
      "  'm/VBP\n",
      "  (NP currenlty/JJ working/NN)\n",
      "  in/IN\n",
      "  Easy/NNP\n",
      "  Way/NNP\n",
      "  Agency/NNP\n",
      "  and/CC\n",
      "  my/PRP$\n",
      "  salary/JJ\n",
      "  is/VBZ\n",
      "  55000/-/JJ)\n"
     ]
    }
   ],
   "source": [
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse(sent)\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('My', 'PRP$', 'O'),\n",
      " ('name', 'NN', 'B-NP'),\n",
      " ('is', 'VBZ', 'O'),\n",
      " ('Muhammad', 'NNP', 'O'),\n",
      " ('Shahzad', 'NNP', 'O'),\n",
      " ('Ahsan', 'NNP', 'O'),\n",
      " ('.', '.', 'O'),\n",
      " ('I', 'PRP', 'O'),\n",
      " (\"'m\", 'VBP', 'O'),\n",
      " ('22', 'CD', 'O'),\n",
      " ('years', 'NNS', 'O'),\n",
      " ('old', 'JJ', 'O'),\n",
      " ('.', '.', 'O'),\n",
      " ('I', 'PRP', 'O'),\n",
      " (\"'m\", 'VBP', 'O'),\n",
      " ('currenlty', 'JJ', 'B-NP'),\n",
      " ('working', 'NN', 'I-NP'),\n",
      " ('in', 'IN', 'O'),\n",
      " ('Easy', 'NNP', 'O'),\n",
      " ('Way', 'NNP', 'O'),\n",
      " ('Agency', 'NNP', 'O'),\n",
      " ('and', 'CC', 'O'),\n",
      " ('my', 'PRP$', 'O'),\n",
      " ('salary', 'JJ', 'O'),\n",
      " ('is', 'VBZ', 'O'),\n",
      " ('55000/-', 'JJ', 'O')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint\n",
    "iob_tagged = tree2conlltags(cs)\n",
    "pprint(iob_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Shahzad\n",
      "[nltk_data]     Ahsan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Shahzad\n",
      "[nltk_data]     Ahsan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  My/PRP$\n",
      "  name/NN\n",
      "  is/VBZ\n",
      "  (PERSON Muhammad/NNP Shahzad/NNP Ahsan/NNP)\n",
      "  ./.\n",
      "  I/PRP\n",
      "  'm/VBP\n",
      "  22/CD\n",
      "  years/NNS\n",
      "  old/JJ\n",
      "  ./.\n",
      "  I/PRP\n",
      "  'm/VBP\n",
      "  currenlty/JJ\n",
      "  working/NN\n",
      "  in/IN\n",
      "  (GPE Easy/NNP)\n",
      "  Way/NNP\n",
      "  Agency/NNP\n",
      "  and/CC\n",
      "  my/PRP$\n",
      "  salary/JJ\n",
      "  is/VBZ\n",
      "  55000/-/JJ)\n"
     ]
    }
   ],
   "source": [
    "from nltk import ne_chunk\n",
    "ne_tree = ne_chunk(pos_tag(word_tokenize(ex)))\n",
    "print(ne_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
